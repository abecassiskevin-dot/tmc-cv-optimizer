#!/usr/bin/env python3
"""
TMC Universal CV Enricher
Lit n'importe quel CV ‚Üí Enrichit avec IA ‚Üí G√©n√®re CV TMC professionnel
"""

import os
import sys
import json
from docxtpl import DocxTemplate, RichText
from docx import Document
import jinja2
from typing import Dict, List, Any
import PyPDF2
import re
from zipfile import ZipFile
from xml.etree import ElementTree as ET

# === NOUVEAUX IMPORTS POUR OCR ===
from pdf2image import convert_from_path
import pytesseract
from PIL import Image
import tempfile

print(">>> tmc_universal_enricher module loading", flush=True)


def fix_table_width_to_auto(doc):
    """
    Change table width from fixed to auto to prevent horizontal shift after merge.
    
    This fixes the issue where Skills Matrix tables with fixed width (e.g., 8.1 inches)
    get shifted right after merging because they don't fit within the page margins.
    
    Args:
        doc: Document object to fix
    
    Returns:
        int: Number of tables fixed
    """
    w = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'
    tables_fixed = 0
    
    for table in doc.tables:
        tbl = table._element
        tblPr = tbl.find(f'.//{w}tblPr')
        
        if tblPr is not None:
            # Find and fix tblW (table width)
            tblW = tblPr.find(f'.//{w}tblW')
            if tblW is not None:
                old_type = tblW.get(f'{w}type', 'unknown')
                old_w = tblW.get(f'{w}w', 'unknown')
                
                # Change to auto width
                tblW.set(f'{w}type', 'auto')
                tblW.set(f'{w}w', '0')
                
                print(f"   üîß Table width changed: {old_type}={old_w} ‚Üí auto=0")
                tables_fixed += 1
            
            # Remove fixed layout if present
            tblLayout = tblPr.find(f'.//{w}tblLayout')
            if tblLayout is not None:
                old_layout = tblLayout.get(f'{w}type', 'unknown')
                tblPr.remove(tblLayout)
                print(f"   üîß Removed tblLayout: {old_layout}")
    
    return tables_fixed


class TMCUniversalEnricher:
    """Enrichisseur universel de CV au format TMC"""
    
    def __init__(self, api_key: str = None):
        """Initialiser avec cl√© API Claude"""
        self.api_key = api_key or os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            raise ValueError("‚ùå Cl√© API Claude manquante! D√©finissez ANTHROPIC_API_KEY dans les secrets Streamlit ou en variable d'environnement.")
        
        # Debug cl√© API
        print(f">>> ANTHROPIC_KEY_PRESENT: {bool(self.api_key)}, len: {len(self.api_key) if self.api_key else 0}", flush=True)
        
        # Ne cr√©e PAS le client ici (lazy loading)
        self._anthropic_client = None
    
    def _get_anthropic_client(self):
        """Lazy loading du client Anthropic"""
        if self._anthropic_client is None:
            try:
                print(">>> Creating anthropic client", flush=True)
                import anthropic
                # Cr√©ation SIMPLE du client pour version 0.25.9
                self._anthropic_client = anthropic.Anthropic(api_key=self.api_key)
                print(">>> Anthropic client created OK", flush=True)
            except Exception as e:
                print(f">>> ERROR creating anthropic client: {repr(e)}", flush=True)
                raise
        return self._anthropic_client
    
    # ========================================
    # MODULE 1 : EXTRACTION UNIVERSELLE
    # ========================================
    
    def detect_file_type(self, file_path: str) -> str:
        """D√©tecter le type de fichier"""
        ext = file_path.lower().split('.')[-1]
        if ext == 'pdf':
            return 'pdf'
        elif ext in ['docx', 'doc']:
            return 'docx'
        elif ext in ['txt', 'text']:
            return 'txt'
        else:
            return 'unknown'
    
    def extract_from_pdf(self, file_path: str) -> str:
        """
        Extraire texte d'un PDF avec fallback OCR automatique
        1. Essaye PyPDF2 pour texte s√©lectionnable
        2. Si √©chec/texte vide ‚Üí Utilise OCR sur images
        """
        print(f"üìÑ Extracting PDF: {file_path}", flush=True)
        
        try:
            # ===== √âTAPE 1: Tentative extraction PyPDF2 =====
            text = []
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                num_pages = len(pdf_reader.pages)
                print(f"üìä PDF has {num_pages} pages", flush=True)
                
                for page_num, page in enumerate(pdf_reader.pages, 1):
                    page_text = page.extract_text()
                    if page_text:
                        text.append(page_text)
                    print(f"  Page {page_num}: {len(page_text) if page_text else 0} chars", flush=True)
            
            extracted_text = "\n".join(text).strip()
            
            # ===== V√âRIFIER SI L'EXTRACTION A FONCTIONN√â =====
            # Seuil: Si moins de 100 caract√®res ou trop peu de mots ‚Üí C'est scann√©
            word_count = len(extracted_text.split())
            char_count = len(extracted_text)
            
            print(f"üìà PyPDF2 extraction: {char_count} chars, {word_count} words", flush=True)
            
            # Si extraction suffisante ‚Üí Retourner
            if char_count > 100 and word_count > 20:
                print("‚úÖ PDF text extraction successful (text-based PDF)", flush=True)
                return extracted_text
            
            # ===== √âTAPE 2: PDF scann√© d√©tect√© ‚Üí OCR =====
            print("‚ö†Ô∏è PDF appears to be scanned (image-based). Switching to OCR...", flush=True)
            return self._extract_from_pdf_ocr(file_path)
            
        except Exception as e:
            print(f"‚ùå Error in PDF extraction: {e}", flush=True)
            # En cas d'erreur PyPDF2, essayer quand m√™me OCR
            try:
                print("üîÑ Trying OCR as fallback...", flush=True)
                return self._extract_from_pdf_ocr(file_path)
            except Exception as e2:
                print(f"‚ùå OCR fallback also failed: {e2}", flush=True)
                return ""
    
    def _extract_from_pdf_ocr(self, file_path: str) -> str:
        """
        Extraire texte d'un PDF scann√© via OCR
        Utilise pdf2image + pytesseract
        """
        print("üîç Starting OCR extraction...", flush=True)
        
        try:
            # Convertir PDF en images (une par page)
            # poppler_path peut √™tre n√©cessaire sur Windows, mais pas sur Linux/Render
            images = convert_from_path(
                file_path,
                dpi=300,  # Haute r√©solution pour meilleur OCR
                fmt='jpeg',
                thread_count=2  # Parall√©lisation
            )
            
            print(f"üì∑ Converted {len(images)} pages to images", flush=True)
            
            # Extraire texte de chaque image
            all_text = []
            for i, image in enumerate(images, 1):
                print(f"  üîé OCR processing page {i}/{len(images)}...", flush=True)
                
                # Appliquer OCR avec config optimis√©e
                # lang='eng+fra' pour anglais ET fran√ßais
                page_text = pytesseract.image_to_string(
                    image,
                    lang='eng+fra',  # Anglais + Fran√ßais
                    config='--psm 1 --oem 3'  # PSM 1 = automatic page segmentation with OSD
                )
                
                if page_text.strip():
                    all_text.append(f"--- Page {i} ---\n{page_text}")
                    print(f"  ‚úì Page {i}: {len(page_text)} chars extracted", flush=True)
            
            extracted_text = "\n\n".join(all_text)
            print(f"‚úÖ OCR extraction complete: {len(extracted_text)} chars total", flush=True)
            
            return extracted_text
            
        except Exception as e:
            print(f"‚ùå OCR extraction failed: {e}", flush=True)
            import traceback
            print(traceback.format_exc(), flush=True)
            return ""
    
     
    def extract_from_docx(self, file_path: str) -> str:
        """Extraire texte d'un Word + zones textes"""
        try:
            doc = Document(file_path)
            text = []
            
            # Paragraphes normaux
            for para in doc.paragraphs:
                if para.text.strip():
                    text.append(para.text.strip())
            
            # Tableaux
            for table in doc.tables:
                for row in table.rows:
                    row_text = " | ".join([cell.text.strip() for cell in row.cells if cell.text.strip()])
                    if row_text:
                        text.append(row_text)
            
            # NOUVEAU : Extraire les zones textes du XML
            textbox_content = self.extract_textboxes(file_path)
            if textbox_content:
                text.append("\n=== ZONES TEXTES ===")
                text.extend(textbox_content)
            
            return "\n".join(text)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur extraction Word: {e}")
            return ""
    def extract_from_txt(self, file_path: str) -> str:
        """Extraire texte d'un fichier texte"""
        try:
            # Essayer plusieurs encodages
            for encoding in ['utf-8', 'latin-1', 'cp1252']:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        return f.read()
                except UnicodeDecodeError:
                    continue
            # Si tout √©choue, ignorer les erreurs
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur extraction TXT: {e}")
            return ""
    
    def extract_textboxes(self, docx_path: str) -> list:
        """Extraire le contenu des zones textes (text boxes) du XML"""
        textboxes = []
        
        try:
            with ZipFile(docx_path, 'r') as docx:
                # Lire le document.xml
                xml_content = docx.read('word/document.xml')
                tree = ET.fromstring(xml_content)
                
                # Namespaces Word
                namespaces = {
                    'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main',
                    'v': 'urn:schemas-microsoft-com:vml',
                    'w10': 'urn:schemas-microsoft-com:office:word'
                }
                
                # Chercher tous les √©l√©ments de texte dans les zones textes
                # Les zones textes sont dans w:txbxContent
                for txbx in tree.findall('.//w:txbxContent', namespaces):
                    texts = []
                    for t in txbx.findall('.//w:t', namespaces):
                        if t.text:
                            texts.append(t.text.strip())
                    if texts:
                        textboxes.append(' '.join(texts))
                
                # Aussi chercher dans v:textbox (ancien format)
                for vtxbx in tree.findall('.//v:textbox', namespaces):
                    texts = []
                    for t in vtxbx.findall('.//w:t', namespaces):
                        if t.text:
                            texts.append(t.text.strip())
                    if texts:
                        textboxes.append(' '.join(texts))
                        
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur extraction zones textes: {e}")
        
        return textboxes
    
    def extract_cv_text(self, cv_path: str) -> str:
        """Extraction universelle - d√©tecte et extrait selon le type"""
        print(f"üìÑ Extraction du CV: {cv_path}")
        
        file_type = self.detect_file_type(cv_path)
        
        if file_type == 'pdf':
            print("   Format d√©tect√©: PDF")
            return self.extract_from_pdf(cv_path)
        elif file_type == 'docx':
            print("   Format d√©tect√©: Word")
            return self.extract_from_docx(cv_path)
        elif file_type == 'txt':
            print("   Format d√©tect√©: Texte")
            return self.extract_from_txt(cv_path)
        else:
            raise ValueError(f"‚ùå Format non support√©: {file_type}")

    # ========================================
    # MODULE 2 : PARSING INTELLIGENT
    # ========================================
    
    def parse_cv_with_claude(self, cv_text: str) -> Dict[str, Any]:
        """Parser le CV avec Claude pour extraire les infos structur√©es"""
        print("ü§ñ Parsing du CV avec Claude AI...", flush=True)
        
        try:
            client = self._get_anthropic_client()
            
            prompt = f"""Tu es un expert en analyse de CV. Extrait TOUTES les informations de ce CV et structure-les en JSON.

CV √Ä ANALYSER:
{cv_text}

IMPORTANT CRITIQUE:
- Le NOM peut √™tre cach√© dans un tableau HTML ou √™tre stylis√©. Cherche PARTOUT.
- Le LIEU DE R√âSIDENCE est OBLIGATOIRE : cherche "Montr√©al", "Montreal", villes + pays (ex: "Montreal CA", "Montr√©al, Canada", "Toronto ON", etc.). Si introuvable, mets "Location not specified".
- Les LANGUES sont OBLIGATOIRES : cherche "Fran√ßais", "French", "English", "Anglais", "Bilingual", "Bilingue", etc. Si introuvable, mets ["Not specified"].

Extrait et structure en JSON STRICT (sans markdown):
{{
  "nom_complet": "Nom Pr√©nom du candidat (cherche PARTOUT, m√™me dans tableaux/HTML)",
  "titre_professionnel": "Titre/poste actuel",
  "profil_resume": "R√©sum√© du profil si pr√©sent (sinon vide)",
  "lieu_residence": "OBLIGATOIRE - Ville, Pays (ex: Montr√©al, Canada) ou Montreal CA. Cherche codes pays (CA, US, FR). Si vraiment introuvable: 'Location not specified'",
  "langues": ["OBLIGATOIRE - Fran√ßais", "Anglais", ... Cherche 'bilingual', 'French', 'English', etc. Si introuvable: ['Not specified']],
  "competences": ["comp√©tence1", "comp√©tence2", "comp√©tence3", ...],
  "experiences": [
    {{
      "periode": "2020-2023",
      "entreprise": "Nom entreprise",
      "poste": "Titre du poste",
      "responsabilites": ["t√¢che 1", "t√¢che 2", "t√¢che 3"]
    }}
  ],
  "formation": [
    {{
      "diplome": "Nom COMPLET du dipl√¥me",
      "institution": "Nom √©cole/universit√©",
      "annee": "2020 (ou p√©riode exacte)",
      "pays": "Canada"
    }}
  ],
  "certifications": [
    {{
      "nom": "Nom certification",
      "organisme": "Organisme",
      "annee": "2023"
    }}
  ],
  "projets": [
    {{
      "nom": "Nom projet",
      "description": "Description courte"
    }}
  ]
}}

R√àGLES CRITIQUES:
- Le NOM est PRIORITAIRE - cherche dans tout le texte (tableaux, d√©but, fin)
- LIEU DE R√âSIDENCE : cherche formats "Ville, Pays", "Montreal CA", "Montr√©al QC", codes postaux (H2X, etc.)
- LANGUES : cherche "Languages", "Langues", "French", "English", "Bilingual", m√™me dans sections comp√©tences
- Pour les dipl√¥mes: nom COMPLET + ann√©e EXACTE
- Extrait TOUT (ne rate rien)
- Si une section est vide, mets une liste vide []
- Format JSON strict uniquement"""

            print(f">>> Calling Claude API with timeout=300s...", flush=True)
            response = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=8000,
                timeout=300.0,  # 5 minutes max
                messages=[{"role": "user", "content": prompt}]
            )
            print(f">>> API call completed successfully", flush=True)
            
        except Exception as e:
            print(f">>> ERROR calling anthropic for parsing: {repr(e)}", flush=True)
            return {}
        
        response_text = response.content[0].text.strip()
        
        # Nettoyer JSON
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.startswith('```'):
            response_text = response_text[3:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        response_text = response_text.strip()
        
        try:
            parsed_data = json.loads(response_text)
            print(f"‚úÖ Parsing r√©ussi!")
            print(f"   Nom: [ANONYMIZED]")
            print(f"   Langues: {', '.join(parsed_data.get('langues', []))}")
            print(f"   Lieu: [ANONYMIZED]")
            print(f"   Comp√©tences: {len(parsed_data.get('competences', []))}")
            print(f"   Exp√©riences: {len(parsed_data.get('experiences', []))}")
            return parsed_data
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è Erreur JSON: {e}")
            print(f"R√©ponse brute: {response_text[:500]}")
            return {}

    # ========================================
    # MODULE 3 : ENRICHISSEMENT (TON PROMPT)
    # ========================================
    
    def read_job_description(self, jd_path: str) -> str:
        """Lire la job description"""
        file_type = self.detect_file_type(jd_path)
        
        if file_type == 'pdf':
            return self.extract_from_pdf(jd_path)
        elif file_type == 'docx':
            return self.extract_from_docx(jd_path)
        else:
            return self.extract_from_txt(jd_path)
    
    def analyze_cv_matching(self, parsed_cv: Dict[str, Any], jd_text: str) -> Dict[str, Any]:
        """
        Analyser le matching entre CV et JD sans enrichir le contenu.
        Retourne uniquement: score_matching, domaines_analyses, synthese_matching
        """
        import time
        
        print(f"üîç Analyse du matching CV/JD...", flush=True)
        
        start_time = time.time()
        
        try:
            client = self._get_anthropic_client()
            
            # Reconstruire le CV en texte pour le prompt
            cv_text = f"""
PROFIL: {parsed_cv.get('profil_resume', '')}

TITRE: {parsed_cv.get('titre_professionnel', '')}

COMP√âTENCES:
{chr(10).join(['- ' + comp for comp in parsed_cv.get('competences', [])])}

EXP√âRIENCES:
"""
            for exp in parsed_cv.get('experiences', []):
                cv_text += f"\n{exp.get('periode', '')} | {exp.get('entreprise', '')} | {exp.get('poste', '')}\n"
                for resp in exp.get('responsabilites', []):
                    cv_text += f"  - {resp}\n"
            
            cv_text += "\nFORMATION:\n"
            for form in parsed_cv.get('formation', []):
                cv_text += f"- {form.get('diplome', '')} | {form.get('institution', '')} | {form.get('annee', '')}\n"
        
            # PROMPT FOCALIS√â SUR L'ANALYSE DE MATCHING UNIQUEMENT - VERSION ULTRA-STRICTE V1.3.9
            prompt = f"""Tu es un syst√®me d'√©valuation automatis√© ULTRA-STRICT qui analyse le matching entre CV et Job Description.

üéØ ANALYSE DE MATCHING POND√âR√âE (VERSION ULTRA-STRICTE V1.3.9):

‚ö†Ô∏è PRINCIPE FONDAMENTAL - √âVALUATION ULTRA-RIGOUREUSE:
- Tu es un RECRUTEUR SENIOR EXTR√äMEMENT EXIGEANT avec 15+ ans d'exp√©rience
- Tu recrutes pour des postes CRITIQUES o√π l'excellence est la norme
- CHAQUE point doit √™tre M√âRIT√â avec des PREUVES CONCR√àTES du CV
- Si tu h√©sites entre 2 scores ‚Üí TOUJOURS prends le PLUS BAS
- Agis comme si tu recrutais pour ton propre argent (z√©ro tol√©rance pour l'approximation)
- Pour le M√äME CV et la M√äME JD ‚Üí EXACTEMENT le m√™me score √† chaque fois (coh√©rence algorithmique)

üî¥ R√àGLE D'OR - SCORE GLOBAL = SOMME DOMAINES:
- Le score_matching FINAL = somme EXACTE de tous les scores de domaines
- V√âRIFIE 3 FOIS avant de r√©pondre: somme des scores = score_matching
- Si tu calcules 58/100 en sommant les domaines ‚Üí score_matching DOIT √™tre 58
- NE JAMAIS inventer un score global diff√©rent de la somme calcul√©e

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìã √âTAPE 1 - IDENTIFIER 5-8 DOMAINES CRITIQUES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

PROCESSUS AUTOMATIQUE D'IDENTIFICATION:
1. Scan complet de la JD - rep√©rer TOUS les mots techniques/comp√©tences
2. Compter la fr√©quence EXACTE de chaque technologie/comp√©tence/m√©thodologie
3. Identifier les must-haves vs nice-to-haves
4. Cr√©er une liste de domaines par ordre d'importance
5. Appliquer la formule de pond√©ration ci-dessous

üìä FORMULE DE POND√âRATION MATH√âMATIQUE:
Pour chaque domaine, calcule son poids avec:
Poids = (Mentions_JD √ó 10) + (Niveau_requis √ó 5) + Bonus_contexte

O√π:
- Mentions_JD: Nombre de fois mentionn√© dans JD (1=once, 2=2-3 times, 3=4+ times)
- Niveau_requis: Must-have/Required=3, Important=2, Nice-to-have=1
- Bonus_contexte: +5 si dans le titre du poste, +3 si dans top requirements

üí° EXEMPLES DE DOMAINES TYPES:
- Technologies sp√©cifiques (ex: "Python Django", "AWS Lambda", "React Native")
- M√©thodologies (ex: "Agile/Scrum", "ITIL v4", "DevOps CI/CD")
- Comp√©tences m√©tier (ex: "Financial Modeling", "Clinical Trials Management")
- Certifications (ex: "PMP", "AWS Solutions Architect", "CPA")
- Langues avec niveau (ex: "Bilingual French/English C1+", "Spanish Business Level")
- Soft skills MESURABLES (ex: "Team Leadership 10+ people", "Stakeholder Management C-Suite")

‚ö†Ô∏è INTERDICTIONS ABSOLUES:
- NE JAMAIS cr√©er de domaine vague type "General Fit", "Soft Skills", "Cultural Fit"
- NE JAMAIS cr√©er de domaine "bonus" pour ajuster artificiellement le score
- TOUS les domaines doivent √™tre EXPLICITEMENT mentionn√©s dans la JD
- Pas de domaines "catch-all" ou g√©n√©riques

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéØ √âTAPE 2 - GRILLE D'√âVALUATION ULTRA-STRICTE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Pour CHAQUE domaine identifi√©, √©value le score avec cette GRILLE ULTRA-S√âV√àRE (0-100 points par domaine):

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üî¥ NIVEAU 0-15 POINTS: QUASI-AUCUNE COMP√âTENCE
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
0 points: Comp√©tence TOTALEMENT absente du CV (aucune mention directe ou indirecte)
10 points: Mention tr√®s vague OU comp√©tence tangentielle (ex: "exposure to", "familiar with")
15 points: Mention superficielle OU formation th√©orique seulement SANS pratique OU <3 mois d'exp√©rience

üü† NIVEAU 20-35 POINTS: D√âBUTANT/JUNIOR
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
20 points: 3-6 mois d'exp√©rience pratique OU 1 projet simple r√©alis√© sous supervision
25 points: 6-9 mois d'exp√©rience OU 2 projets avec support d'√©quipe
30 points: 9-12 mois d'exp√©rience avec autonomie partielle OU certification r√©cente + pratique limit√©e
35 points: 1 an d'exp√©rience solide avec quelques r√©alisations concr√®tes (mais sans metrics)

üü° NIVEAU 40-55 POINTS: INTERM√âDIAIRE
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
40 points: 1-1.5 ans d'exp√©rience + 2-3 projets pertinents document√©s
45 points: 1.5-2 ans d'exp√©rience + contribution mesurable (ex: "improved X by Y%")
50 points: 2-2.5 ans d'exp√©rience solide + r√©alisations quantifi√©es (metrics, budget, scope)
55 points: 2.5-3 ans + r√¥le de contributeur principal sur projets moyens

üü¢ NIVEAU 60-75 POINTS: CONFIRM√â/SENIOR
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
60 points: 3-4 ans d'exp√©rience confirm√©e + ownership de projets + r√©sultats mesurables
65 points: 4-5 ans + expertise d√©montr√©e par r√©alisations significatives (ex: led team of 5, managed $500K budget)
70 points: 5-6 ans + r√¥le de lead/expert technique + mentorship + process improvements
75 points: 6-7 ans + expertise reconnue EN INTERNE (promotions, leadership technique, formations donn√©es en interne)

üîµ NIVEAU 80-90 POINTS: EXPERT EXCEPTIONNEL
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
80 points: 7-8 ans d'exp√©rience TR√àS solide + leadership prouv√© + expertise reconnue PAR L'INDUSTRIE (speaking engagements, certifications avanc√©es, articles techniques)
85 points: 8-10 ans + contribution MAJEURE √† l'industrie (architecture de solutions complexes multi-millions, thought leadership, certifications rares)
90 points: 10-12 ans + expertise de NIVEAU MONDIAL dans ce domaine sp√©cifique (publications acad√©miques/industrie, conf√©rences internationales, mentor d'experts, awards/recognition)

üèÜ NIVEAU 95-100 POINTS: QUASI-IMPOSSIBLE - TOP 0.1% MONDIAL
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
95 points: 12-15 ans + reconnaissance INTERNATIONALE + contributions MAJEURES √† l'√©volution du domaine (patents, standards, books, keynote speaker top conferences)
100 points: R√âSERV√â AUX L√âGENDES VIVANTES - 15+ ans + autorit√© MONDIALE incontest√©e dans le domaine + impact transformationnel sur l'industrie (ex: cr√©ateur de framework utilis√© par millions, membre de comit√©s internationaux, consultant pour Fortune 10)

‚ö†Ô∏è R√àGLES ULTRA-STRICTES D'ATTRIBUTION:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. JAMAIS de score ‚â•60 sans PREUVES QUANTIFI√âES concr√®tes dans le CV
2. JAMAIS de score ‚â•75 sans leadership/mentorship/expertise reconnue PROUV√âE
3. JAMAIS de score ‚â•85 sans contributions MAJEURES √† l'industrie (publications, speaking, thought leadership)
4. JAMAIS de score ‚â•95 sans reconnaissance INTERNATIONALE v√©rifiable
5. Si le CV mentionne l'exp√©rience en ann√©es SEULEMENT sans d√©tails de r√©alisations ‚Üí score MAX = 55
6. Si aucun metric/chiffre fourni pour un domaine ‚Üí score MAX = 50
7. Si le candidat change de domaine/technologie fr√©quemment (job hopping) ‚Üí p√©nalit√© de -10 points
8. Certifications SANS exp√©rience pratique associ√©e ‚Üí score MAX = 30
9. Exp√©rience dans environnement non-professionnel (side projects, freelance) compte pour 50% seulement
10. Si tu h√©sites entre 2 scores ‚Üí TOUJOURS choisir le PLUS BAS

‚öôÔ∏è R√àGLES DE CALCUL FINAL:
1. Score brut du domaine = √©valuation selon grille ci-dessus (0-100)
2. Score pond√©r√© = (score_brut √ó poids) / 100
3. Score_max du domaine = poids

Exemple d√©taill√©:
- Domaine: "Python Backend Development" | Poids: 25%
- Candidat: 4.5 ans d'exp√©rience Python, 3 projets document√©s, led team of 3, aucune publication
- √âvaluation: Entre 60 et 65 points ‚Üí choisir 60 (r√®gle du plus bas)
- Score pond√©r√©: (60 √ó 25) / 100 = 15 points
- Score_max: 25 points
- Notation: 15/25

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìä √âTAPE 3 - CALCULER LE SCORE TOTAL
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Score_matching = SOMME de tous les scores pond√©r√©s (arrondi √† l'entier)

Exemple:
15 (Python) + 10 (AWS) + 8 (Agile) + 12 (API Design) + 9 (PostgreSQL) + 7 (Docker) = 61/100

‚ö†Ô∏è V√âRIFICATIONS FINALES OBLIGATOIRES:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. Somme des poids = EXACTEMENT 100%
2. Score_matching = somme EXACTE des scores pond√©r√©s
3. Si score > 80 ‚Üí TRIPLE-CHECK: y a-t-il vraiment des preuves d'expertise exceptionnelle?
4. Si score > 90 ‚Üí QUADRUPLE-CHECK: est-ce vraiment un candidat top 1% mondial? (la r√©ponse devrait presque toujours √™tre NON)
5. Refaire le calcul 2 fois pour confirmer

üéØ PHILOSOPHIE DE NOTATION ATTENDUE (distribution r√©aliste):
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
- Score 95-100: <1% des candidats (quasi-impossible, r√©serv√© aux l√©gendes)
- Score 85-94: ~5% (top performers exceptionnels)
- Score 75-84: ~15% (tr√®s bons candidats confirm√©s)
- Score 65-74: ~25% (bons candidats solides)
- Score 50-64: ~30% (candidats acceptables avec gaps)
- Score <50: ~24% (candidats insuffisants)

‚ö†Ô∏è DERNI√àRE V√âRIFICATION AVANT R√âPONSE:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Pose-toi ces questions pour CHAQUE domaine o√π tu as donn√© ‚â•60 points:
- Ai-je des PREUVES CONCR√àTES d'exp√©rience quantifiable dans le CV?
- Ai-je des R√âALISATIONS MESURABLES (metrics, budget, team size, impact)?
- Le candidat a-t-il eu un r√¥le de LEADERSHIP/OWNERSHIP d√©montr√©?
- Pour les scores ‚â•85: y a-t-il des contributions √† l'INDUSTRIE (publications, speaking, thought leadership)?
Si la r√©ponse n'est pas un OUI cat√©gorique avec preuves multiples ‚Üí BAISSE le score.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìù √âTAPE 4 - SYNTH√àSE EXECUTIVE (4-5 LIGNES MAX)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

R√©dige une synth√®se ULTRA-CONCISE en 4-5 LIGNES (80-100 mots maximum) qui:

STRUCTURE OBLIGATOIRE (1 paragraphe fluide):
1. Lead with match level + score (e.g., "GOOD match (73/100) for [Role]")
2. Highlight 2-3 TOP strengths with brief evidence (years, key achievement, metric)
3. Mention 1-2 minor gaps or "nice-to-haves" missing
4. End with clear recommendation: "Interview - [reason]" or "Pass - [reason]"

EXEMPLE FORMAT:
"GOOD match (73/100) for Senior Full-Stack Developer. Strong Python backend (8 years) with proven cloud migration leadership (60% deployment time reduction). Full-stack capability confirmed with React + modern DevOps. Minor gaps: Kubernetes nice-to-have, limited Montreal-specific experience. Recommendation: Interview - solid technical fit with measurable impact."

R√àGLES CRITIQUES:
- MAX 4-5 lignes (80-100 mots)
- NO paragraphs, NO bullet points - juste 1 bloc de texte fluide
- Include score + match level (EXCELLENT 85+, GOOD 70-84, MODERATE 55-69, WEAK <55)
- Be specific with numbers/metrics when available
- Professional but direct tone
- Clear go/no-go recommendation at the end

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìÑ FORMAT DE SORTIE JSON
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìÑ JOB DESCRIPTION:
{jd_text}

üìÑ CV DU CANDIDAT:
{cv_text}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ G√âN√àRE MAINTENANT TON ANALYSE - FORMAT JSON STRICT:

Retourne UNIQUEMENT un JSON avec cette structure (sans texte avant/apr√®s):

{{
    "score_matching": 58,
    "domaines_analyses": [
        {{
            "domaine": "Nom du domaine technique/comp√©tence exact",
            "poids": 20,
            "score": 10,
            "score_max": 20,
            "match": "bon",
            "commentaire": "Justification FACTUELLE ultra-d√©taill√©e bas√©e sur des √©l√©ments PR√âCIS du CV avec ann√©es d'exp√©rience, projets, r√©alisations, metrics. Minimum 2-3 phrases compl√®tes."
        }}
    ],
    "synthese_matching": "COMPREHENSIVE PROFESSIONAL ANALYSIS (4-6 DETAILED PARAGRAPHS, 250-350 WORDS):

[Paragraph 1 - Overall Assessment]
[Detailed assessment text...]

[Paragraph 2 - Top Strengths]
[Detailed strengths text...]

[Paragraph 3 - Partial Matches]
[Detailed partial matches text...]

[Paragraph 4 - Gaps]
[Detailed gaps text...]

[Paragraph 5 - Final Recommendation]
[Detailed recommendation text...]"
}}

‚ö†Ô∏è R√àGLES JSON CRITIQUES:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
- "match" peut √™tre: "excellent" (‚â•85/100), "bon" (65-84), "partiel" (40-64), "incompatible" (<40)
- Tous les scores doivent √™tre des NOMBRES (pas de strings)
- La somme des poids doit faire exactement 100
- Le score_matching doit √™tre la somme exacte des scores de tous les domaines
- Commentaire: minimum 2-3 phrases compl√®tes avec d√©tails factuels pr√©cis du CV
- Synth√®se: MAXIMUM 4-5 lignes (80-100 mots), format executive summary

‚ö†Ô∏è LANGUE: ALL output must be in ENGLISH.
- Domain names in English (e.g., "Python Backend Development", not "D√©veloppement Backend Python")
- All comments in English
- Synthesis in English (4-5 lines max)

G√©n√®re l'analyse maintenant:"""
            
            print(f">>> Calling Claude API for matching analysis...", flush=True)
            
            # ‚úÖ RETRY LOGIC FOR TIMEOUTS
            max_retries = 2
            response = None
            last_error = None
            
            for attempt in range(max_retries):
                try:
                    response = client.messages.create(
                        model="claude-sonnet-4-5-20250929",
                        max_tokens=4000,
                        timeout=900.0,  # 15 minutes
                        messages=[{"role": "user", "content": prompt}]
                    )
                    break  # Success - exit retry loop
                    
                except Exception as e:
                    last_error = e
                    error_name = type(e).__name__
                    
                    # Check if it's a timeout error
                    if 'timeout' in error_name.lower() or 'timeout' in str(e).lower():
                        if attempt < max_retries - 1:
                            print(f"‚è±Ô∏è Timeout attempt {attempt+1}/{max_retries}, retrying...", flush=True)
                            continue
                        else:
                            # Final timeout - return error result
                            print(f"‚ùå Final timeout after {max_retries} attempts", flush=True)
                            return {
                                'error': 'timeout',
                                'score_matching': 0,
                                'domaines_analyses': [],
                                'synthese_matching': "‚è±Ô∏è L'analyse a pris trop de temps (timeout apr√®s plusieurs tentatives). Veuillez r√©essayer avec un CV plus court ou contactez le support."
                            }
                    else:
                        # Other error - re-raise
                        raise
            
            if response is None:
                # Should not happen, but safety check
                raise last_error
            
            # Extraire tokens
            usage = response.usage
            input_tokens = usage.input_tokens
            output_tokens = usage.output_tokens
            total_tokens = input_tokens + output_tokens
            
            print(f">>> API Response received. Tokens: {total_tokens}", flush=True)
            
            # Parser la r√©ponse
            response_text = response.content[0].text.strip()
            
            # Nettoyer le JSON
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.startswith('```'):
                response_text = response_text[3:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            response_text = response_text.strip()
            
            # Parser le JSON
            try:
                matching_result = json.loads(response_text)
                print(f">>> JSON parsed successfully!", flush=True)
                
                # V1.3.4.1 FIX: Recalculer le score_matching pour garantir coh√©rence
                # Somme des scores de tous les domaines
                if 'domaines_analyses' in matching_result and matching_result['domaines_analyses']:
                    calculated_score = sum(d.get('score', 0) for d in matching_result['domaines_analyses'])
                    original_score = matching_result.get('score_matching', 0)
                    
                    # Si diff√©rence > 2 points, utiliser le score calcul√©
                    if abs(calculated_score - original_score) > 2:
                        print(f"‚ö†Ô∏è Score mismatch detected: Claude={original_score}, Calculated={calculated_score}")
                        print(f"   Using calculated score for consistency: {calculated_score}/100")
                        matching_result['score_matching'] = round(calculated_score)
                    else:
                        # Petite diff√©rence acceptable (arrondis)
                        matching_result['score_matching'] = round(calculated_score)
                    
                    # ‚úÖ V1.3.4.2 FIX: CAP SCORE AT 100 MAXIMUM
                    if matching_result['score_matching'] > 100:
                        print(f"‚ö†Ô∏è Score exceeded 100: {matching_result['score_matching']} ‚Üí Capping at 100")
                        matching_result['score_matching'] = 100
                        
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON Error: {e}", flush=True)
                print(f">>> Attempting to fix JSON...", flush=True)
                
                # Tentative de r√©paration
                fix_prompt = f"""The following JSON is malformed. Please fix it and return ONLY the corrected JSON without any explanation or markdown:

{response_text}

Return the corrected JSON directly:"""
                
                # ‚úÖ RETRY LOGIC FOR JSON FIX
                fix_response = None
                for fix_attempt in range(2):
                    try:
                        fix_response = client.messages.create(
                            model="claude-sonnet-4-5-20250929",
                            max_tokens=4000,
                            timeout=300.0,  # 5 minutes for fix
                            messages=[{"role": "user", "content": fix_prompt}]
                        )
                        break
                    except Exception as fix_error:
                        if 'timeout' in type(fix_error).__name__.lower() or 'timeout' in str(fix_error).lower():
                            if fix_attempt < 1:
                                print(f"‚è±Ô∏è JSON fix timeout, retrying...", flush=True)
                                continue
                            else:
                                # Can't fix JSON - return error
                                return {
                                    'error': 'json_parse_timeout',
                                    'score_matching': 0,
                                    'domaines_analyses': [],
                                    'synthese_matching': "‚ùå Erreur de parsing JSON et timeout lors de la correction. Veuillez r√©essayer."
                                }
                        else:
                            raise
                
                if fix_response is None:
                    return {
                        'error': 'json_fix_failed',
                        'score_matching': 0,
                        'domaines_analyses': [],
                        'synthese_matching': "‚ùå Impossible de corriger le JSON malform√©."
                    }
                
                fixed_text = fix_response.content[0].text.strip()
                if fixed_text.startswith('```json'):
                    fixed_text = fixed_text[7:]
                if fixed_text.startswith('```'):
                    fixed_text = fixed_text[3:]
                if fixed_text.endswith('```'):
                    fixed_text = fixed_text[:-3]
                fixed_text = fixed_text.strip()
                
                matching_result = json.loads(fixed_text)
                print(f">>> JSON successfully fixed and parsed!", flush=True)
            
            # Calculer le temps et co√ªt
            processing_time = round(time.time() - start_time, 2)
            cost_input = (input_tokens / 1_000_000) * 3.0
            cost_output = (output_tokens / 1_000_000) * 15.0
            total_cost = round(cost_input + cost_output, 4)
            
            # Ajouter les m√©tadonn√©es
            matching_result['_metadata'] = {
                'processing_time_seconds': processing_time,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'total_tokens': total_tokens,
                'estimated_cost_usd': total_cost
            }
            
            print(f"‚úÖ Analyse de matching r√©ussie!")
            print(f"   Score matching: {matching_result.get('score_matching', 0)}/100")
            print(f"   Domaines analys√©s: {len(matching_result.get('domaines_analyses', []))}")
            print(f"   ‚è±Ô∏è Temps: {processing_time}s")
            print(f"   üìä Tokens: {total_tokens:,}")
            print(f"   üí∞ Co√ªt: ${total_cost}")
            
            return matching_result
            
        except Exception as e:
            print(f"‚ùå Erreur analyse matching: {e}", flush=True)
            import traceback
            print(traceback.format_exc(), flush=True)
            return {
                'score_matching': 0,
                'domaines_analyses': [],
                'synthese_matching': f'Erreur lors de l\'analyse: {str(e)}'
            }
    
    def enrich_cv_with_prompt(
        self, 
        parsed_cv: Dict[str, Any], 
        jd_text: str, 
        language: str = "French",
        matching_analysis: Dict[str, Any] = None  # ‚úÖ FIX: Nouveau param√®tre pour r√©utiliser le matching
    ) -> Dict[str, Any]:
        """
        Enrichir le CV avec l'IA
        
        Args:
            parsed_cv: CV pars√©
            jd_text: Job Description
            language: Langue cible (French/English)
            matching_analysis: R√©sultat optionnel du matching pr√©alable (Step 1)
                              Si fourni, r√©utilise le score au lieu de le recalculer
        
        Returns:
            CV enrichi avec tous les champs n√©cessaires
        """
        import time
        
        # ‚ö†Ô∏è CRITICIAL: D√©terminer si on r√©utilise le scoring du Step 1
        reuse_scoring = matching_analysis is not None
        
        print(f"‚ú® Enrichissement du CV avec l'IA...", flush=True)
        print(f"   Langue cible: {language}", flush=True)
        print(f"   Mode: {'R√©utilisation scoring Step 1' if reuse_scoring else 'Scoring complet'}", flush=True)
        
        # ‚è±Ô∏è D√©marrer le chronom√®tre
        start_time = time.time()
        
        try:
            client = self._get_anthropic_client()
            
            # Reconstruire le CV en texte pour le prompt
            cv_text = f"""
PROFIL: {parsed_cv.get('profil_resume', '')}

TITRE: {parsed_cv.get('titre_professionnel', '')}

COMP√âTENCES:
{chr(10).join(['- ' + comp for comp in parsed_cv.get('competences', [])])}

EXP√âRIENCES:
"""
            for exp in parsed_cv.get('experiences', []):
                cv_text += f"\n{exp.get('periode', '')} | {exp.get('entreprise', '')} | {exp.get('poste', '')}\n"
                for resp in exp.get('responsabilites', []):
                    cv_text += f"  - {resp}\n"
            
            cv_text += "\nFORMATION:\n"
            for form in parsed_cv.get('formation', []):
                cv_text += f"- {form.get('diplome', '')} | {form.get('institution', '')} | {form.get('annee', '')}\n"
        
            # PROMPT ULTRA-RENFORC√â POUR COH√âRENCE ABSOLUE
            language_instruction = f"""
üö® R√àGLE ABSOLUE - LANGUE {language.upper()} üö®
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö†Ô∏è INSTRUCTION CRITIQUE - LANGUE OBLIGATOIRE: {language.upper()}

Tu DOIS g√©n√©rer 100% du contenu en {language} - AUCUNE EXCEPTION:
‚úì Le TITRE PROFESSIONNEL en {language}
‚úì Le PROFIL ENRICHI en {language}
‚úì TOUTES les COMP√âTENCES en {language}
‚úì TOUTES les EXP√âRIENCES en {language}
‚úì TOUS les noms de cat√©gories en {language}
‚úì TOUTES les descriptions en {language}
‚úì TOUS les mots-cl√©s en {language}

üî¥ SI {language} = "French":
- Utilise: "Analyste", "Gestion", "Configuration", "D√©veloppement", "Senior"
- PAS: "Analyst", "Management", "Development"
- Exemple titre: "Analyste QA Senior" ‚úì (PAS "Senior QA Analyst" ‚úó)
- Exemple description: "Configuration de SharePoint incluant gestion..."
- Style: Fran√ßais professionnel standard

üî¥ SI {language} = "English":
- Utilise: "Analyst", "Management", "Configuration", "Development", "Senior"
- PAS: "Analyste", "Gestion", "D√©veloppement"
- Exemple titre: "Senior QA Analyst" ‚úì (PAS "Analyste QA Senior" ‚úó)
- Exemple description: "SharePoint configuration including management..."
- Style: Professional English standard

IMPORTANT TITRE PROFESSIONNEL:
- Adapte le titre √† la Job Description
- Le titre doit √™tre COURT (3-5 mots maximum)
- Le titre doit √™tre en {language} - V√âRIFIE 2 FOIS
- Si langue = French: ordre fran√ßais (ex: "Analyste Configuration SharePoint")
- Si langue = English: ordre anglais (ex: "SharePoint Configuration Analyst")

V√âRIFICATION FINALE OBLIGATOIRE:
Avant de r√©pondre, relis TOUT ton JSON et confirme que:
1. Le titre_professionnel_enrichi est en {language} ‚úì
2. Le profil_enrichi est en {language} ‚úì
3. Toutes les cat√©gories de comp√©tences sont en {language} ‚úì
4. Toutes les descriptions sont en {language} ‚úì
5. Les responsabilit√©s des exp√©riences sont en {language} ‚úì

Si UNE SEULE phrase n'est pas en {language} ‚Üí RECOMMENCE TOUT.

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ R√îLE CRITIQUE - TU ES UN RECRUTEUR SENIOR PROFESSIONNEL:
- Tu as 15+ ans d'exp√©rience en recrutement technique
- Tu travailles pour le CLIENT (l'entreprise qui recrute)
- Ta mission: √©valuer si le CANDIDAT correspond EXACTEMENT aux besoins du CLIENT
- Tu dois √™tre OBJECTIF, RIGOUREUX et REPRODUCTIBLE dans ton √©valuation
- Ton scoring doit √™tre IDENTIQUE si tu analyses le m√™me CV/JD plusieurs fois
- Tu notes comme un examinateur professionnel, pas comme un vendeur
"""
            
            # ‚úÖ FIX: Choisir le prompt selon si on r√©utilise le matching ou non
            if reuse_scoring:
                # ============================================
                # VERSION SIMPLIFI√âE - Matching d√©j√† fait au Step 1
                # ============================================
                prompt = f"""Voici la job description et le CV actuel ci-dessous.

üîπ Am√©liore le CV pour qu'il soit parfaitement align√© avec la job description tout en gardant le format d'origine (titres, mise en page, structure, ton professionnel).
{language_instruction}

‚ö†Ô∏è IMPORTANT: L'analyse de matching a D√âJ√Ä √©t√© faite. Tu dois UNIQUEMENT faire l'ENRICHISSEMENT du contenu.

Fais :

1. Une version r√©√©crite et enrichie du CV

2a. TITRE: TITRE COURT adapt√© √† la JD en {language} (3-5 mots max)

2b. PROFIL exceptionnel : √©cris un paragraphe NARRATIF fluide (pas de liste), 5-6 lignes avec progression logique.

2c. GRAS ULTRA-S√âLECTIF : identifie UNIQUEMENT 3-5 technologies CRITIQUES.

3. Int√®gre naturellement les mots-cl√©s techniques de la JD
4. Ajuste les intitul√©s pour que le profil paraisse livrable imm√©diatement
5. N'invente rien ‚Äî reformule uniquement les √©l√©ments pr√©sents
6. EXP√âRIENCES : bullets courts (1 ligne max), maximum 5-6 bullets par exp√©rience

R√©ponds en JSON STRICT (sans markdown) avec cette structure:
{{
  "titre_professionnel_enrichi": "TITRE COURT en {language} (3-5 mots max)",
  
  "profil_enrichi": "Profil NARRATIF 5-6 lignes en {language} avec **3-5 technologies cl√©s** en gras",
  
  "mots_cles_a_mettre_en_gras": ["Liste 15-20 TECHNOLOGIES de la JD - PAS de verbes g√©n√©riques"],
  
  "competences_enrichies": {{
    "Nom Cat√©gorie 1 (3-6 mots max)": [
      "**Technologie principale** : description en 2-3 lignes (MAXIMUM 100-150 caract√®res) incluant contexte, outils associ√©s (**outil1**, **outil2**) et r√©sultats. Style concis et percutant.",
      "**Autre technologie** : description COURTE avec contexte + outils (**tech1**, **tech2**) + impact. 2-3 technologies en **gras** par comp√©tence."
    ],
    "Nom Cat√©gorie 2": [
      "Comp√©tence concise..."
    ]
  }},
  
  R√àGLES ULTRA-CRITIQUES pour les comp√©tences (NON-N√âGOCIABLE):
  - Noms de cat√©gories COURTS (3-6 mots max)
  - 5-6 cat√©gories ADAPT√âES √† la JD
  - Chaque cat√©gorie: 3-5 comp√©tences MAXIMUM
  - CHAQUE comp√©tence : 2-3 LIGNES MAXIMUM (100-150 caract√®res) - NE PAS D√âPASSER
  - Format: "**Technologie** : description concise avec outils (**outil1**, **outil2**) + r√©sultats"
  - 2-3 technologies en **gras** par comp√©tence (PAS PLUS)
  - Descriptions CONCISES, CLAIRES et PROFESSIONNELLES
  - Privil√©gier CLART√â et CONCISION sur la longueur
  
  "experiences_enrichies": [
    {{
      "periode": "2020-2023",
      "entreprise": "Nom entreprise",
      "poste": "Titre reformul√© selon JD",
      "responsabilites": [
        "Configuration **Open edX** incluant structuration et int√©gration avec **SharePoint** pour gestion contenus",
        "Automatisation processus documentaires via **Power Automate** et **Teams** pour am√©liorer efficacit√©"
      ],
      "environment": "**Open edX**, **SharePoint**, **Microsoft 365**, Teams, Power Automate, OneDrive, SQL"
    }}
  ]
}}

FORMAT OBLIGATOIRE (COPIER format comp√©tences):
- Responsabilit√©s: Technologies **isol√©es** dans texte normal (ex: "Configuration **Tech1** incluant **Tech2** pour r√©sultats")
- Environnement: Liste virgules avec 3-5 technologies **critiques** en gras, autres sans
- JAMAIS phrases enti√®res en gras
- Maximum 2-3 mots entre **ast√©risques**

---

JOB DESCRIPTION:
{jd_text}

---

CV ACTUEL:
{cv_text}

---

IMPORTANT FINAL - R√àGLES JSON STRICTES:
- G√©n√®re UNIQUEMENT du JSON valide
- PAS de commentaires (// ou /* */)
- PAS de virgules finales (trailing commas)
- PAS de markdown (```json ou ```)
- TOUS les strings doivent utiliser des guillemets doubles ""
- V√©rifie que TOUTES les accolades et crochets sont ferm√©s
- Si tu h√©sites sur un champ, mets une valeur par d√©faut plut√¥t qu'une erreur

R√©ponds UNIQUEMENT avec du JSON pur, sans rien d'autre avant ou apr√®s."""

            else:
                # ============================================
                # VERSION COMPL√àTE - Mode legacy/fallback avec matching inclus
                # ============================================
                prompt = f"""Voici la job description et le CV actuel ci-dessous.

üîπ Am√©liore le CV pour qu'il soit parfaitement align√© avec la job description tout en gardant le format d'origine (titres, mise en page, structure, ton professionnel).
{language_instruction}

üéØ ANALYSE DE MATCHING POND√âR√âE (ULTRA-CRITIQUE - COH√âRENCE ABSOLUE REQUISE):

‚ö†Ô∏è PRINCIPE FONDAMENTAL DE COH√âRENCE - M√âTHODOLOGIE STRICTE:
- Tu es un SYST√àME D'√âVALUATION AUTOMATIS√â, pas un humain
- Pour le M√äME CV et la M√äME JD ‚Üí EXACTEMENT le m√™me score √† chaque fois
- Utilise une grille d'√©valuation MATH√âMATIQUE et REPRODUCTIBLE
- Agis comme un ALGORITHME, pas comme un recruteur subjectif
- Chaque crit√®re suit des r√®gles BINAIRES strictes (oui/non, pr√©sent/absent)
- Tu DOIS pouvoir justifier CHAQUE point attribu√© avec des FAITS du CV
- Si tu h√©sites entre 2 scores ‚Üí prends le PLUS BAS (principe de strictness)

üî¥ R√àGLE D'OR - SCORE GLOBAL = SOMME DOMAINES:
- Le score_matching FINAL = somme EXACTE de tous les scores de domaines
- V√âRIFIE 3 FOIS avant de r√©pondre: somme des scores = score_matching
- Si tu calcules 37/100 en sommant les domaines ‚Üí score_matching DOIT √™tre 37
- NE JAMAIS inventer un score global diff√©rent de la somme calcul√©e

√âTAPE 1 - IDENTIFIER 5-8 DOMAINES CRITIQUES (M√âTHODE ALGORITHIMQUE):

üìã PROCESSUS AUTOMATIQUE D'IDENTIFICATION:
1. Scan complet de la JD - rep√©rer TOUS les mots techniques
2. Compter la fr√©quence EXACTE de chaque technologie/comp√©tence
3. Cr√©er une liste de domaines par ordre d'importance
4. Appliquer la formule de pond√©ration ci-dessous

üìä FORMULE DE POND√âRATION MATH√âMATIQUE:
Pour chaque domaine, calcule son poids avec:

Poids_Base = (Nombre_mentions / Total_mentions_techniques) √ó 100

Bonus:
- +20% si c'est le TITRE du poste (ex: ".NET Developer" ‚Üí Stack .NET = +20%)
- +15% si mots "Required", "Must have", "Essential", "Critical"
- +10% si mentionn√© dans les 3 premi√®res lignes de la JD
- +5% par occurrence au-del√† de 3 mentions

Poids_Final = min(Poids_Base + Bonus, 50%)  ‚Üê Aucun domaine ne peut d√©passer 50%

R√àGLES STRICTES DE POND√âRATION:
- Stack technique principal (dans titre ou 5+ mentions): 30-50%
- Comp√©tences techniques secondaires (3-4 mentions): 15-25%
- Comp√©tences techniques tertiaires (1-2 mentions): 5-15%
- Soft skills/Leadership: MAXIMUM 10% (sauf si poste management)
- TOTAL des poids = EXACTEMENT 100% (v√©rifie avec calculatrice)
- Si total ‚â† 100%, ajuste proportionnellement tous les poids

√âTAPE 2 - SCORER CHAQUE DOMAINE (ALGORITHME DE NOTATION STRICT):

ü§ñ SYST√àME DE NOTATION AUTOMATIS√â - APPLIQUE CES R√àGLES EXACTEMENT:

POUR CHAQUE DOMAINE, COMPTE:
a) Nombre de mentions EXACTES de la technologie dans le CV
b) Nombre de projets/exp√©riences utilisant cette technologie  
c) Dur√©e totale d'utilisation (ann√©es)
d) Niveau d√©montr√© (junior/interm√©diaire/senior)

üìê FORMULE MATH√âMATIQUE DE SCORING:

√âtape 2A - Score Brut (0-100%):
‚Ä¢ 0% : Z√âRO mention de la techno dans le CV, stack incompatible
‚Ä¢ 10% : Technologie proche mentionn√©e (PostgreSQL pour SQL Server)
‚Ä¢ 25% : 1 mention + aucune exp√©rience pratique (formation seulement)
‚Ä¢ 40% : 1-2 mentions + 1 projet + <1 an d'exp√©rience
‚Ä¢ 60% : 3-4 mentions + 2 projets + 1-2 ans d'exp√©rience
‚Ä¢ 80% : 5+ mentions + 3+ projets + 3+ ans d'exp√©rience
‚Ä¢ 100% : 7+ mentions + expertise d√©montr√©e + senior confirm√©

√âtape 2B - Ajustements OBLIGATOIRES:
‚Ä¢ Si stack incompatible (Java vs .NET) ‚Üí Score = 0% (NON-N√âGOCIABLE)
‚Ä¢ Si technologie absente du CV ‚Üí Score = 0% (NON-N√âGOCIABLE)
‚Ä¢ Si aucune exp√©rience pratique prouv√©e ‚Üí Score MAX = 30%
‚Ä¢ Si exp√©rience <1 an ‚Üí Score MAX = 50%
‚Ä¢ Si niveau junior √©vident ‚Üí Score MAX = 60%

√âtape 2C - Calcul Final:
Score_Domaine = (Score_Brut √ó Poids_Domaine) / 100

EXEMPLE D√âTAILL√â:
Domaine: ".NET Development" - Poids: 40%
CV candidat: AUCUNE mention .NET, seulement Java
‚Üí Score_Brut = 0%
‚Üí Score_Domaine = (0 √ó 40) / 100 = 0 points
‚Üí Commentaire: "‚ùå Stack incompatible - profil Java exclusif"

üî¥ V√âRIFICATION FINALE OBLIGATOIRE:
Somme_Scores = Œ£(tous les Score_Domaine)
Si Somme_Scores ‚â† score_matching ‚Üí ERREUR CRITIQUE ‚Üí RECALCULE

√âTAPE 3 - COMMENTAIRE PAR DOMAINE (30-50 mots):
- Utilise ‚ùå (0-30%), ‚ö†Ô∏è (30-70%), ‚úÖ (70-100%)
- Sois FACTUEL et OBJECTIF dans tes commentaires
- Base-toi UNIQUEMENT sur les FAITS pr√©sents dans le CV
- Ne fais PAS d'hypoth√®ses optimistes

EXEMPLE:
JD demande: ".NET, C#, Azure, SQL Server"
Candidat a: "Java, AWS, PostgreSQL"

R√âSULTAT:
{{
  "domaines_analyses": [
    {{
      "domaine": "Stack .NET (C#, ASP.NET Core, Entity Framework)",
      "poids": 40,
      "score": 0,
      "score_max": 40,
      "commentaire": "‚ùå Aucune exp√©rience .NET/C#. Profil Java exclusivement - incompatibilit√© majeure sur stack principale.",
      "match": "incompatible"
    }},
    {{
      "domaine": "Cloud Microsoft Azure",
      "poids": 20,
      "score": 8,
      "score_max": 20,
      "commentaire": "‚ö†Ô∏è Exp√©rience AWS uniquement. Comp√©tences cloud transf√©rables mais n√©cessite formation Azure.",
      "match": "partiel"
    }},
    {{
      "domaine": "SQL Server & T-SQL",
      "poids": 15,
      "score": 10,
      "score_max": 15,
      "commentaire": "‚úÖ Ma√Ætrise PostgreSQL et MySQL - comp√©tences SQL transf√©rables √† SQL Server.",
      "match": "bon"
    }}
  ],
  "score_matching": 45,
  "synthese_matching": "PARTIAL MATCH (45/100) - This Java senior profile presents significant challenges for a .NET-focused role, though some transferable competencies exist.

KEY STRENGTHS: The candidate brings 8+ years of enterprise software development experience with proven expertise in cloud platforms (AWS/Azure) and database technologies (PostgreSQL, MySQL). Their experience leading technical teams and architecting scalable solutions demonstrates strong senior-level capabilities. The containerization skills (Docker, Kubernetes) mentioned in their current role are highly relevant.

PARTIAL MATCHES: While the candidate's SQL database experience is strong and transferable to SQL Server, their cloud platform knowledge (AWS/Azure fundamentals) provides a foundation that could accelerate learning of Azure-specific services required for this role. Their experience with agile methodologies and team leadership aligns well with the position's requirements.

CRITICAL GAPS: The most significant concern is the complete absence of .NET stack experience (C#, ASP.NET, Entity Framework), which represents 40% of the role's core requirements (0/40 points). The candidate would require substantial retraining on the entire Microsoft technology stack. Additionally, there's no evidence of Azure-specific service experience (Azure Functions, Service Bus, etc.) beyond basic cloud concepts.

RECOMMENDATION: This profile requires major reconversion and is NOT recommended for immediate placement. Consider only if: (1) the client accepts a 3-6 month ramp-up period, (2) candidate demonstrates strong motivation to transition to .NET, and (3) budget allows for extensive training investment. For urgent needs, seek candidates with existing .NET experience."
}}

Fais :

1. ANALYSE POND√âR√âE OBLIGATOIRE (voir ci-dessus)
2. Une version r√©√©crite et enrichie du CV

2b. PROFIL exceptionnel : √©cris un paragraphe NARRATIF fluide (pas de liste), 5-6 lignes avec progression logique.

2c. GRAS ULTRA-S√âLECTIF : identifie UNIQUEMENT 3-5 technologies CRITIQUES.

3. Int√®gre naturellement les mots-cl√©s techniques de la JD
4. Ajuste les intitul√©s pour que le profil paraisse livrable imm√©diatement
5. N'invente rien ‚Äî reformule uniquement les √©l√©ments pr√©sents
6. EXP√âRIENCES : bullets courts (1 ligne max), maximum 5-6 bullets par exp√©rience

R√©ponds en JSON STRICT (sans markdown) avec cette structure:
{{
  "domaines_analyses": [
    {{
      "domaine": "Nom domaine technique/fonctionnel (ex: Stack .NET, Cloud Azure)",
      "poids": 40,
      "score": 15,
      "score_max": 40,
      "commentaire": "Explication 30-50 mots avec ‚ùå/‚ö†Ô∏è/‚úÖ",
      "match": "incompatible|partiel|bon|excellent"
    }}
  ],
  "score_matching": 45,
  "synthese_matching": "CONCISE PROFESSIONAL SUMMARY (1 paragraph, 80-120 words):
  
  Write a single comprehensive paragraph that includes:
  - Match level (Excellent/Strong/Good/Partial/Weak) with the score (X/100)
  - Candidate's years of experience and seniority level
  - Top 2-3 strongest domains that align perfectly with requirements
  - 1-2 areas that are partial matches or transferable skills
  - 1-2 critical gaps if any
  - Brief recommendation (Recommend/Conditional/Not Recommend)
  
  Keep it analytical and professional. Use concrete examples from the CV. Be honest about both strengths and weaknesses. Make it scannable for busy recruiters. ALWAYS WRITE IN ENGLISH.",
  
  "titre_professionnel_enrichi": "TITRE COURT en {language} (3-5 mots max)",
  
  "profil_enrichi": "Profil NARRATIF 5-6 lignes en {language} avec **3-5 technologies cl√©s** en gras",
  
  "mots_cles_a_mettre_en_gras": ["Liste 15-20 TECHNOLOGIES de la JD - PAS de verbes g√©n√©riques"],
  
  "competences_enrichies": {{
    "Nom Cat√©gorie 1 (3-6 mots max)": [
      "**Technologie principale** : description en 2-3 lignes (MAXIMUM 100-150 caract√®res) incluant contexte, outils associ√©s (**outil1**, **outil2**) et r√©sultats. Style concis et percutant.",
      "**Autre technologie** : description COURTE avec contexte + outils (**tech1**, **tech2**) + impact. 2-3 technologies en **gras** par comp√©tence."
    ],
    "Nom Cat√©gorie 2": [
      "Comp√©tence concise..."
    ]
  }},
  
  R√àGLES ULTRA-CRITIQUES pour les comp√©tences (NON-N√âGOCIABLE):
  - Noms de cat√©gories COURTS (3-6 mots max)
  - 5-6 cat√©gories ADAPT√âES √† la JD
  - Chaque cat√©gorie: 3-5 comp√©tences MAXIMUM
  - CHAQUE comp√©tence : 2-3 LIGNES MAXIMUM (100-150 caract√®res) - NE PAS D√âPASSER
  - Format: "**Technologie** : description concise avec outils (**outil1**, **outil2**) + r√©sultats"
  - 2-3 technologies en **gras** par comp√©tence (PAS PLUS)
  - Descriptions CONCISES, CLAIRES et PROFESSIONNELLES
  - Privil√©gier CLART√â et CONCISION sur la longueur
  
  "experiences_enrichies": [
    {{
      "periode": "2020-2023",
      "entreprise": "Nom entreprise",
      "poste": "Titre reformul√© selon JD",
      "responsabilites": [
        "Configuration **Open edX** incluant structuration et int√©gration avec **SharePoint** pour gestion contenus",
        "Automatisation processus documentaires via **Power Automate** et **Teams** pour am√©liorer efficacit√©"
      ],
      "environment": "**Open edX**, **SharePoint**, **Microsoft 365**, Teams, Power Automate, OneDrive, SQL"
    }}
  ],
  
  FORMAT OBLIGATOIRE (COPIER format comp√©tences):
  - Responsabilit√©s: Technologies **isol√©es** dans texte normal (ex: "Configuration **Tech1** incluant **Tech2** pour r√©sultats")
  - Environnement: Liste virgules avec 3-5 technologies **critiques** en gras, autres sans
  - JAMAIS phrases enti√®res en gras
  - Maximum 2-3 mots entre **ast√©risques**
  
  "score_matching": 45,
  "points_forts": ["ALWAYS in English: key strength 1", "ALWAYS in English: key strength 2"]
}}

üåç CRITICAL LANGUAGE REQUIREMENT:
- 'domaines_analyses' (domain names AND comments) MUST ALWAYS be in ENGLISH
- 'synthese_matching' MUST ALWAYS be in ENGLISH  
- 'points_forts' MUST ALWAYS be in ENGLISH
- Example domain: "SQL Data Extraction and Manipulation" NOT "Extraction de donn√©es SQL"
- Example comment: "‚ùå No demonstrated experience in SQL data extraction..." NOT "‚ùå Aucune exp√©rience..."
- Example synthesis: "Java senior profile unsuitable for .NET position..." NOT "Profil Java senior inadapt√©..."

CRITICAL SCORING RULES:
- 'domaines_analyses' MUST be completed with 5-8 domains totaling EXACTLY 100%
- BE STRICT on scoring - don't give points if candidate lacks the skill
- If stack mismatch (Java vs .NET), give 0 points, not 40-50

üî¥üî¥üî¥ V√âRIFICATION FINALE AVANT R√âPONSE (NON-N√âGOCIABLE) üî¥üî¥üî¥

AVANT de g√©n√©rer ta r√©ponse JSON, tu DOIS:

1Ô∏è‚É£ CALCULER LA SOMME:
   Somme = domaine1.score + domaine2.score + domaine3.score + ... + domaineN.score
   
2Ô∏è‚É£ V√âRIFIER:
   Si Somme ‚â† score_matching ‚Üí ERREUR ‚Üí RECALCULE TOUT
   
3Ô∏è‚É£ V√âRIFIER LES POIDS:
   Somme_Poids = domaine1.poids + domaine2.poids + ... + domaineN.poids
   Si Somme_Poids ‚â† 100 ‚Üí ERREUR ‚Üí RECALCULE TOUT
   
4Ô∏è‚É£ DOUBLE-CHECK:
   Pour chaque domaine: v√©rifie que score ‚â§ score_max
   Pour chaque domaine: v√©rifie que score_max = poids

EXEMPLE DE V√âRIFICATION:
Domaine 1: Stack .NET (40%) ‚Üí 0/40 points
Domaine 2: Cloud Azure (20%) ‚Üí 8/20 points  
Domaine 3: SQL Server (15%) ‚Üí 10/15 points
Domaine 4: DevOps (15%) ‚Üí 5/15 points
Domaine 5: Agile (10%) ‚Üí 7/10 points

V√©rification poids: 40+20+15+15+10 = 100 ‚úÖ
V√©rification score: 0+8+10+5+7 = 30 ‚úÖ
Donc: score_matching = 30 ‚úÖ

Si tu trouves une incoh√©rence ‚Üí RECALCULE TOUT depuis le d√©but

---

JOB DESCRIPTION:
{jd_text}

---

CV ACTUEL:
{cv_text}

---

IMPORTANT FINAL - R√àGLES JSON STRICTES:
- G√©n√®re UNIQUEMENT du JSON valide
- PAS de commentaires (// ou /* */)
- PAS de virgules finales (trailing commas)
- PAS de markdown (```json ou ```)
- TOUS les strings doivent utiliser des guillemets doubles ""
- V√©rifie que TOUTES les accolades et crochets sont ferm√©s
- Si tu h√©sites sur un champ, mets une valeur par d√©faut plut√¥t qu'une erreur

R√©ponds UNIQUEMENT avec du JSON pur, sans rien d'autre avant ou apr√®s."""

            print(f">>> Calling Claude API for enrichment with timeout=300s...", flush=True)
            response = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=8000,
                timeout=300.0,  # 5 minutes max
                messages=[{"role": "user", "content": prompt}]
            )
            print(f">>> Enrichment API call completed successfully", flush=True)
            
            # üìä Capturer les m√©tadonn√©es API
            input_tokens = response.usage.input_tokens if hasattr(response, 'usage') else 0
            output_tokens = response.usage.output_tokens if hasattr(response, 'usage') else 0
            total_tokens = input_tokens + output_tokens
            
        except Exception as e:
            print(f">>> ERROR calling anthropic for enrichment: {repr(e)}", flush=True)
            import traceback
            print(f">>> FULL TRACEBACK:\n{traceback.format_exc()}", flush=True)
            return {}
        
        print(f">>> API Response received, extracting text...", flush=True)
        response_text = response.content[0].text.strip()
        print(f">>> Response length: {len(response_text)} characters", flush=True)
        print(f">>> Response preview (first 500 chars):\n{response_text[:500]}", flush=True)
        
        # Nettoyer JSON
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.startswith('```'):
            response_text = response_text[3:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        response_text = response_text.strip()
        
        print(f">>> Attempting to parse JSON...", flush=True)
        
        # üîß NOUVEAU: Tentative de parsing avec retry et correction
        enriched = None
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                if attempt == 0:
                    # Premi√®re tentative: parsing direct
                    enriched = json.loads(response_text)
                    print(f">>> JSON parsed successfully on first attempt!", flush=True)
                    break
                else:
                    # Tentatives suivantes: demander √† Claude de corriger le JSON
                    print(f">>> Retry {attempt}/{max_retries-1}: Asking Claude to fix JSON...", flush=True)
                    
                    fix_prompt = f"""The following JSON is malformed. Please fix it and return ONLY the corrected JSON without any explanation or markdown:

{response_text}

Return the corrected JSON directly:"""
                    
                    fix_response = client.messages.create(
                        model="claude-sonnet-4-5-20250929",
                        max_tokens=8000,
                        timeout=60.0,
                        messages=[{"role": "user", "content": fix_prompt}]
                    )
                    
                    fixed_text = fix_response.content[0].text.strip()
                    # Nettoyer le JSON corrig√©
                    if fixed_text.startswith('```json'):
                        fixed_text = fixed_text[7:]
                    if fixed_text.startswith('```'):
                        fixed_text = fixed_text[3:]
                    if fixed_text.endswith('```'):
                        fixed_text = fixed_text[:-3]
                    fixed_text = fixed_text.strip()
                    
                    enriched = json.loads(fixed_text)
                    print(f">>> JSON successfully fixed and parsed on attempt {attempt}!", flush=True)
                    break
                    
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è Erreur JSON (attempt {attempt + 1}/{max_retries}): {e}", flush=True)
                if attempt == 0:
                    print(f">>> JSON Error position: {e.pos}", flush=True)
                    print(f">>> Problematic section: {response_text[max(0, e.pos-100):e.pos+100]}", flush=True)
                
                if attempt == max_retries - 1:
                    # Dernier essai √©chou√©: retourner dict vide
                    print(f">>> All parsing attempts failed. Returning empty dict.", flush=True)
                    print(f">>> Full response text:\n{response_text}", flush=True)
                    return {}
                else:
                    # Continuer au prochain retry
                    continue
        
        if enriched is None:
            print(f">>> ERROR: enriched is None after all retries", flush=True)
            return {}
        
        print(f">>> Keys in enriched: {list(enriched.keys())}", flush=True)
        
        # ‚è±Ô∏è Calculer le temps de traitement
        processing_time = round(time.time() - start_time, 2)
        
        # üí∞ Calculer le co√ªt (prix Claude Sonnet 4.5: $3/MTok input, $15/MTok output)
        cost_input = (input_tokens / 1_000_000) * 3.0
        cost_output = (output_tokens / 1_000_000) * 15.0
        total_cost = round(cost_input + cost_output, 4)
        
        # üìà Ajouter les m√©tadonn√©es dans le r√©sultat
        enriched['_metadata'] = {
            'processing_time_seconds': processing_time,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'total_tokens': total_tokens,
            'estimated_cost_usd': total_cost
        }
        
        print(f"‚úÖ Enrichissement r√©ussi!")
        
        # ‚úÖ FIX: Si on r√©utilise le matching, merger les r√©sultats
        if reuse_scoring and matching_analysis:
            print(f"   Mode: R√©utilisation du matching du Step 1", flush=True)
            # R√©cup√©rer les r√©sultats du Step 1
            enriched['score_matching'] = matching_analysis.get('score_matching', 0)
            enriched['domaines_analyses'] = matching_analysis.get('domaines_analyses', [])
            enriched['synthese_matching'] = matching_analysis.get('synthese_matching', '')
            enriched['points_forts'] = matching_analysis.get('points_forts', [])
            print(f"   Score r√©utilis√©: {enriched['score_matching']}/100")
            print(f"   Domaines r√©utilis√©s: {len(enriched['domaines_analyses'])}")
        else:
            print(f"   Mode: Calcul complet du matching", flush=True)
            print(f"   Score matching: {enriched.get('score_matching', 0)}/100")
            print(f"   Domaines analys√©s: {len(enriched.get('domaines_analyses', []))}")
        print(f"   Mots-cl√©s en gras: {len(enriched.get('mots_cles_a_mettre_en_gras', []))}")
        print(f"   ‚è±Ô∏è Temps de traitement: {processing_time}s")
        print(f"   üìä Tokens: {total_tokens:,} ({input_tokens:,} in + {output_tokens:,} out)")
        print(f"   üí∞ Co√ªt estim√©: ${total_cost}")
        
        if enriched.get('domaines_analyses'):
            print(f"\n   üìä D√©tail scoring:")
            for domaine in enriched['domaines_analyses']:
                emoji = domaine.get('match', '')
                if emoji == 'incompatible':
                    emoji = '‚ùå'
                elif emoji == 'partiel':
                    emoji = '‚ö†Ô∏è'
                elif emoji in ['bon', 'excellent']:
                    emoji = '‚úÖ'
                print(f"      {emoji} {domaine.get('domaine', 'N/A')}: {domaine.get('score', 0)}/{domaine.get('score_max', 0)} ({domaine.get('poids', 0)}%)")
        
        # DEBUG: Afficher une responsabilit√© pour voir le format
        if enriched.get('experiences_enrichies'):
            first_exp = enriched['experiences_enrichies'][0]
            if first_exp.get('responsabilites'):
                print(f"\nüîç DEBUG - Premi√®re responsabilit√© :")
                print(f"   {first_exp['responsabilites'][0]}")
            if first_exp.get('environment'):
                print(f"\nüîç DEBUG - Environnement :")
                print(f"   {first_exp['environment']}")
        
        # üö® V√©rification critique: le dict ne doit pas √™tre vide
        if not enriched:
            print(f">>> WARNING: enriched dict is EMPTY!", flush=True)
            return {}
        
        # V√©rifier les cl√©s essentielles
        required_keys = ['score_matching', 'domaines_analyses', 'profil_enrichi']
        missing_keys = [k for k in required_keys if k not in enriched]
        if missing_keys:
            print(f">>> WARNING: Missing critical keys: {missing_keys}", flush=True)
            print(f">>> Available keys: {list(enriched.keys())}", flush=True)
        
        return enriched

    # ========================================
    # MODULE 4 : MAPPING TMC + RICHTEXT
    # ========================================
    
    def mdbold_to_richtext(self, s: str) -> RichText:
        """Convertit les **bold** markdown en RichText propre sans cascade de gras."""
        import re
        rt = RichText()
        pattern = re.compile(r'\*\*(.*?)\*\*')
        last_end = 0

        # Ajouter le texte avant chaque bloc en gras
        for match in pattern.finditer(s):
            if match.start() > last_end:
                rt.add(s[last_end:match.start()], bold=False, font='Arial')
            # Le texte entre **...** est en gras
            rt.add(match.group(1), bold=True, font='Arial')
            last_end = match.end()

        # Ajouter le texte apr√®s le dernier bloc
        if last_end < len(s):
            rt.add(s[last_end:], bold=False, font='Arial')

        return rt

    def map_to_tmc_structure(self, parsed_cv: Dict[str, Any], enriched_cv: Dict[str, Any], template_lang: str = 'FR') -> Dict[str, Any]:
        """Mapper les donn√©es enrichies vers la structure TMC"""
        print("üó∫Ô∏è  Mapping vers structure TMC...")
        
        # 1. PROFIL - Convertir en RichText pour supporter le gras (pas d'√©chappement)
        profil_brut = enriched_cv.get('profil_enrichi', parsed_cv.get('profil_resume', ''))
        profil = self.mdbold_to_richtext(profil_brut) if profil_brut else ''
        
        # 2. COMP√âTENCES - FORMAT CAT√âGORIS√â D√âTAILL√â
        competences_enrichies = enriched_cv.get('competences_enrichies', {})
        
        # Si competences_enrichies est un dict (nouveau format), l'utiliser directement
        if isinstance(competences_enrichies, dict):
            # Supprimer la cl√© "NOTE" si pr√©sente
            skills_categorized = {k: v for k, v in competences_enrichies.items() if k != 'NOTE' and isinstance(v, list)}
        else:
            # Fallback ancien format (liste simple)
            competences = competences_enrichies if isinstance(competences_enrichies, list) else parsed_cv.get('competences', [])
            skills_categorized = {
                'Comp√©tences techniques': competences[:8] if len(competences) >= 8 else competences,
                'Comp√©tences transversales': competences[8:12] if len(competences) > 8 else []
            }
            # Supprimer les cat√©gories vides
            skills_categorized = {k: v for k, v in skills_categorized.items() if v}
        
        # üî• Transformation en RichText pour le formatage (pas d'√©chappement)
        skills_categorized_doc = []
        for cat, skills in skills_categorized.items():
            rt_cat = RichText()
            rt_cat.add(cat, bold=True)
            rt_skills = [self.mdbold_to_richtext(s) for s in skills]
            skills_categorized_doc.append((rt_cat, rt_skills))
        
        # 3. EXP√âRIENCES - Texte simple pour les responsabilit√©s, RichText pour environnement
        experiences_enrichies = enriched_cv.get('experiences_enrichies', parsed_cv.get('experiences', []))
        work_experience = []
        
        for exp in experiences_enrichies:
            # GARDER les responsabilit√©s en TEXTE SIMPLE (pas RichText) - pas d'√©chappement
            responsabilites_text = [r for r in exp.get('responsabilites', [])]
            
            # Convertir l'environnement en RichText pour le gras - pas d'√©chappement
            environment_brut = exp.get('environment', '')
            environment_rt = self.mdbold_to_richtext(environment_brut) if environment_brut else ''
            
            work_exp = {
                'period': exp.get('periode', ''),
                'company': exp.get('entreprise', ''),
                'position': exp.get('poste', ''),
                'general_responsibilities': responsabilites_text,  # Texte simple
                'environment': environment_rt
            }
            work_experience.append(work_exp)
        
        # 4. FORMATION (avec d√©tails complets)
        formation = parsed_cv.get('formation', [])
        education = []
        for form in formation:
            education.append({
                'institution': form.get('institution', ''),
                'degree': form.get('diplome', ''),
                'graduation_year': form.get('annee', 'Date inconnue'),
                'country': form.get('pays', 'Canada'),
                'level': '',
                'title': form.get('diplome', '')
            })
        
        # 5. CERTIFICATIONS (avec mapping vers format template)
        certifications_raw = parsed_cv.get('certifications', [])
        certifications = []
        for cert in certifications_raw:
            certifications.append({
                'name': cert.get('nom', cert.get('name', '')),
                'institution': cert.get('organisme', cert.get('institution', '')),
                'year': str(cert.get('annee', cert.get('year', ''))),
                'country': cert.get('pays', cert.get('country', ''))
            })
        
        # 6. PROJETS
        projects = parsed_cv.get('projets', [])
        
        # 7. INFORMATIONS PERSONNELLES
        nom_complet = parsed_cv.get('nom_complet', '')
        
        # S√©parer pr√©nom et nom
        parts = nom_complet.split() if nom_complet else []
        if len(parts) >= 2:
            first_name = parts[0]
            last_name = ' '.join(parts[1:])
        elif len(parts) == 1:
            first_name = parts[0]
            last_name = ''
        else:
            first_name = 'Pr√©nom'
            last_name = 'Nom'
        
        titre_professionnel = enriched_cv.get('titre_professionnel_enrichi', parsed_cv.get('titre_professionnel', ''))
        lieu_residence = parsed_cv.get('lieu_residence', 'Montr√©al, Canada')
        langues_list = parsed_cv.get('langues', ['Fran√ßais', 'Anglais'])
        
        # Traduire les langues selon le template
        if template_lang == 'FR':
            # Si template FR, traduire de l'anglais vers le fran√ßais
            langue_map = {
                'English': 'Anglais',
                'French': 'Fran√ßais',
                'Hebrew': 'H√©breu',
                'Russian': 'Russe',
                'Spanish': 'Espagnol',
                'German': 'Allemand',
                'Italian': 'Italien',
                'Portuguese': 'Portugais',
                'Chinese': 'Chinois',
                'Japanese': 'Japonais',
                'Arabic': 'Arabe'
            }
            langues_list = [langue_map.get(lang, lang) for lang in langues_list]
        
        langues = ', '.join(langues_list)
        
        context = {
            # Pour le header (minuscules) - PAS d'√©chappement
            'first_name': first_name,
            'last_name': last_name,
            'title': titre_professionnel,
            
            # Pour la page 1 (MAJUSCULES) - PAS d'√©chappement
            'FIRST_NAME': first_name.upper(),
            'LAST_NAME': last_name.upper(),
            'TITLE': titre_professionnel,
            'RESIDENCY': lieu_residence,
            'LANGUAGES': langues,
            
            # AUSSI en minuscules pour compatibilit√© template
            'residency': lieu_residence,
            'languages': langues,
            
            # Reste du CV
            'summary': profil,
            'skills_categorized': skills_categorized,
            'skills_categorized_doc': skills_categorized_doc,  # üî• Version RichText pour le template
            'work_experience': work_experience,
            'education': education,
            'projects': projects,
            'certifications': certifications
        }
        
        print(f"‚úÖ Mapping termin√©!")
        print(f"   Nom: [ANONYMIZED]")
        print(f"   Titre: {titre_professionnel}")
        print(f"   Langues: {langues}")
        print(f"   Profil: RichText g√©n√©r√©")
        total_competences = sum(len(v) for v in skills_categorized.values() if isinstance(v, list))
        print(f"   Cat√©gories: {len(skills_categorized)}")
        print(f"   Comp√©tences: {total_competences}")
        print(f"   Exp√©riences: {len(work_experience)}")
        
        return context

    # ========================================
    # MODULE 5 : G√âN√âRATION DOCX TMC
    # ========================================
    
    def find_template_file(self, template_name: str = "TMC_NA_template_FR.docx") -> str:
        """Recherche intelligente du template dans plusieurs emplacements possibles"""
        from pathlib import Path
        
        # Liste exhaustive des endroits possibles
        script_dir = Path(__file__).parent
        possible_paths = [
            Path(template_name),  # Current directory
            script_dir / template_name,  # Script directory
            script_dir.parent / "branding" / "templates" / template_name,  # ../../branding/templates/
            script_dir.parent.parent / "branding" / "templates" / template_name,  # ../../../branding/templates/
            Path.home() / template_name,  # Home directory
            Path.home() / "tmc-cv-optimizer" / "branding" / "templates" / template_name,  # Project in home
            Path("/app/branding/templates") / template_name,  # Render deployment path
            Path("/home/ubuntu/tmc-cv-optimizer/branding/templates") / template_name,  # Ubuntu deployment
        ]
        
        # Chercher dans les variables d'environnement aussi
        env_template_path = os.getenv("TMC_TEMPLATE_PATH")
        if env_template_path:
            possible_paths.insert(0, Path(env_template_path))
        
        print(f"   üîç Recherche du template: {template_name}")
        
        for path in possible_paths:
            try:
                if path.exists() and path.is_file():
                    print(f"   ‚úÖ Template trouv√©: {path.resolve()}")
                    return str(path.resolve())
            except (OSError, PermissionError) as e:
                # Ignorer silencieusement les erreurs de permissions
                continue
        
        # Si pas trouv√©, afficher tous les chemins essay√©s
        print(f"   ‚ùå Template introuvable: {template_name}")
        print(f"   Chemins test√©s:")
        for path in possible_paths:
            print(f"      - {path}")
        print(f"\n   üí° Astuce: D√©finir TMC_TEMPLATE_PATH pour sp√©cifier un emplacement personnalis√©")
        raise FileNotFoundError(f"Template TMC introuvable: {template_name}")
    
    def generate_tmc_docx(self, context: Dict[str, Any], output_path: str, template_path: str = "TMC_NA_template_FR.docx"):
        """G√©n√©rer le CV TMC final avec docxtpl"""
        print(f"üìù G√©n√©ration du CV TMC: {output_path}")
        
        # üîç RECHERCHE INTELLIGENTE DU TEMPLATE (nouvelle fonction robuste)
        final_template_path = self.find_template_file(template_path)
        print(f"   üìÑ Template: {final_template_path}")
        
        # Cr√©er environnement Jinja2 avec filtre pairwise
        jinja_env = jinja2.Environment()
        
        def pairwise(iterable):
            items = list(iterable)
            result = []
            for i in range(0, len(items), 2):
                if i + 1 < len(items):
                    result.append((items[i], items[i + 1]))
                else:
                    result.append((items[i], ''))
            return result
        
        jinja_env.filters['pairwise'] = pairwise
        
        # üî• Ajouter la fonction r pour RichText dans le contexte
        context['r'] = lambda x: x
        
        # ‚ö†Ô∏è CORRECTION XML : √âchapper les caract√®res sp√©ciaux (¬Æ, &, <, >, etc.)
        from html import escape as html_escape
        print(f"   üîß √âchappement des caract√®res XML sp√©ciaux...")
        
        # √âchapper les champs texte simples
        for key in ['first_name', 'last_name', 'title', 'FIRST_NAME', 'LAST_NAME', 
                   'TITLE', 'residency', 'RESIDENCY', 'languages', 'LANGUAGES']:
            if key in context and isinstance(context[key], str):
                context[key] = html_escape(context[key])
        
        # √âchapper les exp√©riences
        if 'work_experience' in context:
            for exp in context['work_experience']:
                for key in ['period', 'company', 'position']:
                    if key in exp and isinstance(exp[key], str):
                        exp[key] = html_escape(exp[key])
                
                if 'general_responsibilities' in exp and isinstance(exp['general_responsibilities'], list):
                    exp['general_responsibilities'] = [
                        html_escape(r) if isinstance(r, str) else r
                        for r in exp['general_responsibilities']
                    ]
        
        # √âchapper formations
        if 'education' in context:
            for edu in context['education']:
                for key in ['institution', 'degree', 'graduation_year', 'country', 'level', 'title']:
                    if key in edu and isinstance(edu[key], str):
                        edu[key] = html_escape(edu[key])
        
        # √âchapper certifications
        if 'certifications' in context:
            for cert in context['certifications']:
                for key in ['name', 'institution', 'year', 'country']:
                    if key in cert and isinstance(cert[key], str):
                        cert[key] = html_escape(cert[key])
        
        # √âchapper projets
        if 'projects' in context:
            for proj in context['projects']:
                for key in ['nom', 'description']:
                    if key in proj and isinstance(proj[key], str):
                        proj[key] = html_escape(proj[key])
        
        print(f"   ‚úÖ Caract√®res XML √©chapp√©s (¬Æ, &, <, >, etc.)")
        
        # Charger le template TMC
        doc = DocxTemplate(final_template_path)
        
        # Rendre le document
        doc.render(context, jinja_env)
        
        # Sauvegarder
        doc.save(output_path)
        print(f"‚úÖ CV TMC g√©n√©r√© avec succ√®s!")

    def generate_ms_cv_3parts(self, tmc_context, skills_matrix_path, output_path, 
                              cover_template="TMC_NA_template_EN_Anonymise_CoverPage.docx",
                              content_template="TMC_NA_template_EN_Anonymise_Content.docx"):
        """
        G√©n√®re un CV Morgan Stanley en 3 parties:
        1. Cover page (photo + nom + titre + location + langues)
        2. Skills Matrix (upload√©e par le recruteur)
        3. Contenu d√©taill√© (profile + skills + experiences + education)
        
        Args:
            tmc_context: Contexte enrichi du candidat
            skills_matrix_path: Path vers le fichier Skills Matrix upload√©
            output_path: Path pour le fichier final
            cover_template: Template pour la cover page
            content_template: Template pour le contenu d√©taill√©
        
        Returns:
            tuple: (success: bool, output_path: str)
        """
        try:
            from pathlib import Path
            from docxcompose.composer import Composer
            from docx import Document
            import shutil
            
            # Dossier temporaire
            temp_dir = Path("/tmp/cv_optimizer_ms")
            temp_dir.mkdir(exist_ok=True)
            
            # √âTAPE 1: G√©n√©rer cover page
            print("üé® Generating cover page...")
            cover_path = temp_dir / "cover.docx"
            
            # ‚úÖ FIX: Passer seulement le nom du template, find_template_file va le chercher
            print(f"   üìÑ Using cover template: {cover_template}")
            
            self.generate_tmc_docx(
                tmc_context, 
                str(cover_path), 
                template_path=cover_template  # Juste le nom, pas le chemin complet
            )
            print(f"   ‚úÖ Cover page generated: {cover_path.name}")
            
            # √âTAPE 2: Merger cover + Skills Matrix
            print("üîó Merging cover with Skills Matrix...")
            cover_with_skills = temp_dir / "cover_and_skills.docx"
            
            # Charger les deux documents
            cover_doc = Document(str(cover_path))
            skills_doc = Document(skills_matrix_path)
            
            # ‚úÖ V1.3.4.2 FIX: Change table width from fixed to auto to prevent horizontal shift
            print("üîß Fixing Skills Matrix table width...")
            tables_fixed = fix_table_width_to_auto(skills_doc)
            print(f"   ‚úÖ Fixed {tables_fixed} table(s) to auto width")
            
            # V1.3.4 FIX: Ajuster les marges de la Skills Matrix pour correspondre au template
            # Copier les marges du cover vers skills avant merge
            cover_sections = cover_doc.sections
            skills_sections = skills_doc.sections
            
            if cover_sections and skills_sections:
                # Utiliser les marges du template pour la Skills Matrix
                for section in skills_sections:
                    section.top_margin = cover_sections[0].top_margin
                    section.bottom_margin = cover_sections[0].bottom_margin
                    section.left_margin = cover_sections[0].left_margin
                    section.right_margin = cover_sections[0].right_margin
            
            # V1.3.4.1 FIX: Supprimer les espacements au d√©but de la Skills Matrix
            # Ceci assure que le contenu commence exactement en haut de la page
            from docx.shared import Pt
            from docx.oxml import parse_xml
            
            # Supprimer TOUS les paragraphes vides au d√©but du body XML
            # Travailler directement sur body._element pour avoir l'ordre exact
            body = skills_doc.element.body
            elements_to_remove = []
            
            # Parcourir les √©l√©ments dans l'ordre et marquer les paragraphes vides au d√©but
            for elem in body:
                tag = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
                
                if tag == 'p':  # C'est un paragraphe
                    # V√©rifier s'il est vide (pas de texte)
                    ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
                    text_elems = elem.findall('.//w:t', ns)
                    text_content = ''.join([t.text for t in text_elems if t.text])
                    
                    if not text_content.strip():
                        # Paragraphe vide au d√©but ‚Üí marquer pour suppression
                        elements_to_remove.append(elem)
                    else:
                        # Premier paragraphe avec texte ‚Üí arr√™ter
                        break
                elif tag == 'tbl':
                    # On a atteint une table ‚Üí arr√™ter
                    break
            
            # Supprimer les √©l√©ments marqu√©s
            for elem in elements_to_remove:
                body.remove(elem)
            
            print(f"   üßπ Removed {len(elements_to_remove)} empty paragraphs from Skills Matrix")
            
            # R√©initialiser le spacing du premier √©l√©ment restant (si paragraphe)
            if skills_doc.paragraphs:
                first_para = skills_doc.paragraphs[0]
                first_para.paragraph_format.space_before = Pt(0)
                first_para.paragraph_format.space_after = Pt(0)
            
            # Ajouter page break apr√®s cover
            cover_doc.add_page_break()
            
            # Merger avec docxcompose
            composer = Composer(cover_doc)
            composer.append(skills_doc)
            
            # Sauvegarder
            composer.save(str(cover_with_skills))
            print(f"   ‚úÖ Cover + Skills Matrix merged")
            
            # √âTAPE 3: G√©n√©rer contenu d√©taill√©
            print("üìù Generating detailed content...")
            content_path = temp_dir / "content.docx"
            
            # ‚úÖ FIX: Passer seulement le nom du template
            print(f"   üìÑ Using content template: {content_template}")
            
            self.generate_tmc_docx(
                tmc_context,
                str(content_path),
                template_path=content_template  # Juste le nom, pas le chemin complet
            )
            print(f"   ‚úÖ Content generated: {content_path.name}")
            
            # √âTAPE 4: Merger tout ensemble
            print("üîó Merging everything...")
            
            # Charger cover+skills
            final_doc = Document(str(cover_with_skills))
            
            # Ajouter page break avant content
            final_doc.add_page_break()
            
            # Merger avec content
            final_composer = Composer(final_doc)
            content_doc = Document(str(content_path))
            final_composer.append(content_doc)
            
            # Sauvegarder le document final
            final_composer.save(str(output_path))
            print(f"‚úÖ Final CV saved: {output_path}")
            
            # Nettoyer les fichiers temporaires
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            return True, str(output_path)
            
        except Exception as e:
            error_msg = f"Error generating MS CV: {str(e)}"
            print(f"‚ùå {error_msg}")
            import traceback
            traceback.print_exc()
            return False, error_msg
    def apply_bold_post_processing(self, docx_path: str, keywords: list):
        """Post-traiter le document pour mettre en gras les technologies dans les tableaux"""
        print(f"üé® Application du gras sur les technologies...")
        
        from docx import Document as DocxDocument
        from docx.shared import RGBColor
        import re
        
        doc = DocxDocument(docx_path)
        modifications = 0
        
        print(f"   Recherche des **mot** dans le document...")
        
        def apply_bold_to_runs(paragraph):
            """Trouve **mot** et met en gras UNIQUEMENT ce mot"""
            text = paragraph.text
            if '**' not in text:
                return 0
            
            changes = 0
            # Pattern pour trouver **mot**
            pattern = re.compile(r'\*\*([^*]+)\*\*')
            
            # Reconstituer le paragraphe avec le bon formatage
            matches = list(pattern.finditer(text))
            if not matches:
                return 0
            
            # Supprimer tous les runs existants
            for run in paragraph.runs:
                run._element.getparent().remove(run._element)
            
            # Reconstruire avec le bon formatage
            last_end = 0
            for match in matches:
                # Texte normal avant
                if match.start() > last_end:
                    run = paragraph.add_run(text[last_end:match.start()])
                    run.bold = False
                    run.font.name = 'Arial'
                
                # Texte en gras
                run = paragraph.add_run(match.group(1))
                run.bold = True
                run.font.name = 'Arial'
                changes += 1
                
                last_end = match.end()
            
            # Texte normal apr√®s
            if last_end < len(text):
                run = paragraph.add_run(text[last_end:])
                run.bold = False
                run.font.name = 'Arial'
            
            return changes
        
        # Parcourir TOUS les tableaux (o√π sont les exp√©riences)
        print("   üìã Traitement des tableaux...")
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        modifications += apply_bold_to_runs(paragraph)
        
        # Parcourir aussi les paragraphes normaux
        print("   üìù Traitement des paragraphes...")
        for paragraph in doc.paragraphs:
            modifications += apply_bold_to_runs(paragraph)
        
        # Sauvegarder
        doc.save(docx_path)
        if modifications > 0:
            print(f"‚úÖ {modifications} mots mis en gras")
        else:
            print(f"‚ö†Ô∏è Aucun **mot** trouv√©")
        
        return modifications
        
def main():
    """Point d'entr√©e CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(description='TMC Universal CV Enricher')
    parser.add_argument('cv_path', help='Chemin du CV (PDF, Word, etc.)')
    parser.add_argument('jd_path', help='Chemin de la Job Description')
    parser.add_argument('--output', '-o', default='cv_enriched_tmc.docx', help='Fichier de sortie')
    
    args = parser.parse_args()
    
    try:
        enricher = TMCUniversalEnricher()
        
        print("\nüöÄ TMC UNIVERSAL CV ENRICHER")
        print("=" * 60)
        
        # MODULE 1: Extraction
        print("\n[1/5] Extraction du CV...")
        cv_text = enricher.extract_cv_text(args.cv_path)
        print(f"      ‚úÖ {len(cv_text)} caract√®res extraits")
        
        # MODULE 2: Parsing
        print("\n[2/5] Parsing intelligent...")
        parsed_cv = enricher.parse_cv_with_claude(cv_text)
        
        # MODULE 3: Enrichissement
        print("\n[3/5] Enrichissement avec IA...")
        jd_text = enricher.read_job_description(args.jd_path)
        enriched_cv = enricher.enrich_cv_with_prompt(parsed_cv, jd_text)
        
        # MODULE 4: Mapping TMC
        print("\n[4/5] Mapping structure TMC...")
        tmc_context = enricher.map_to_tmc_structure(parsed_cv, enriched_cv)
        
        # MODULE 5: G√©n√©ration
        print("\n[5/5] G√©n√©ration CV final...")
        enricher.generate_tmc_docx(tmc_context, args.output)
        
        # POST-PROCESSING: Application du gras
        print("\n[POST] Application du gras sur mots-cl√©s...")
        keywords = enriched_cv.get('mots_cles_a_mettre_en_gras', [])
        print(f"   Mots-cl√©s √† mettre en gras: {keywords}")
        
        if keywords:
            result = enricher.apply_bold_post_processing(args.output, keywords)
            if result == 0:
                print("   ‚ö†Ô∏è AUCUN mot-cl√© n'a √©t√© mis en gras!")
                print("   V√©rifiez que les mots-cl√©s sont bien dans le CV")
        else:
            print("   ‚ö†Ô∏è Aucun mot-cl√© retourn√© par l'IA")
        
        # R√âSUM√â FINAL
        print("\n" + "=" * 60)
        print("üéâ ENRICHISSEMENT TERMIN√â!")
        print("=" * 60)
        print(f"üìä Score matching: {enriched_cv.get('score_matching', 0)}/100")
        
        # Afficher les domaines analys√©s
        if enriched_cv.get('domaines_analyses'):
            print(f"\nüìä Analyse par domaine:")
            for domaine in enriched_cv['domaines_analyses']:
                match = domaine.get('match', '')
                emoji = '‚ùå' if match == 'incompatible' else '‚ö†Ô∏è' if match == 'partiel' else '‚úÖ'
                print(f"   {emoji} {domaine.get('domaine', 'N/A')}: {domaine.get('score', 0)}/{domaine.get('score_max', 0)} pts ({domaine.get('poids', 0)}%)")
                print(f"      ‚Üí {domaine.get('commentaire', 'N/A')}")
        
        if enriched_cv.get('synthese_matching'):
            print(f"\nüí¨ Synth√®se: {enriched_cv['synthese_matching']}")
        
        print(f"\nüí™ Points forts:")
        for pf in enriched_cv.get('points_forts', [])[:3]:
            print(f"   ‚Ä¢ {pf}")
        print(f"\nüìÑ Fichier g√©n√©r√©: {args.output}")
        print("=" * 60)
        
    except Exception as e:
        print(f"\n‚ùå ERREUR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
